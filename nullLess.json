[
  {
    "id": "1092",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "Through an API, a companys fleet of Amazon EC2 instances collects data from millions of consumers. To guarantee high access rates, the servers batch the data, create an object for each user, and upload the objects to an S3 bucket. Customer ID, Server ID, TS-Server (TimeStamp and Server ID), the objects size, and a timestamp are the objects properties. A developer wishes to locate all items gathered for a particular user during a certain time period. How can the developer accomplish this need after establishing an S3 object created event?",
      "answers": [
        "Run an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the Customer ID as the partition key and the Server ID as the sort key. Retrieve all the records using the Customer ID and Server ID attributes.",
        "Run an AWS Lambda function in response to the S3 object creation events that creates an Amazon Redshift record for every object with the Customer ID as the partition key and TS-Server as the sort key. Retrieve all the records using the Customer ID and TS-Server attributes.",
        "Run an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the Customer ID as the partition key and TS-Server as the sort key. Retrieve all the records using the Customer ID and TS-Server attributes.",
        "Run an AWS Lambda function in response to the S3 object creation events that creates an Amazon Redshift record for every object with the Customer ID as the partition key and the Server ID as the sort key. Retrieve all the records using the Customer ID and Server ID attributes."
      ],
      "correctAnswer": ["Run an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the Customer ID as the partition key and TS-Server as the sort key. Retrieve all the records using the Customer ID and TS-Server attributes."]
    }
  },
  {
    "id": "1093",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A business need a fully managed source control solution that is compatible with AWS. By sharing sets of changes peer-to-peer, the service must guarantee that revision control synchronizes various dispersed repositories. All users must be productive regardless of whether they are connected to a network. Which version control system should I use?",
      "answers": [
        "Subversion",
        "AWS CodeBuild",
        "AWS CodeCommit",
        "AWS CodeStar"
      ],
      "correctAnswer": ["AWS CodeCommit"]
    }
  },
  {
    "id": "1094",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer is tasked with the responsibility of creating a cache layer in front of Amazon RDS. In the event of a service outage, it is costly to regenerate cached material. Which of the following implementations would work best in terms of uptime?",
      "answers": [
        "Implement Amazon ElastiCache Redis in Cluster Mode",
        "Install Redis on an Amazon EC2 instance.",
        "Implement Amazon ElastiCache Memcached.",
        "Migrate the database to Amazon Redshift."
      ],
      "correctAnswer": ["Implement Amazon ElastiCache Redis in Cluster Mode"]
    }
  },
  {
    "id": "1095",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "On an Amazon EC2 instance, a developer is executing an application. When the program attempts to read from an Amazon S3 bucket, it fails. The developer discovers that the S3 read permission is missing from the related IAM role. The developer must enable the application to read from the S3 bucket. Which solution satisfies this need with the MINIMUM amount of application downtime?",
      "answers": [
        "Add the permission to the role. Terminate the existing EC2 instance. Launch a new EC2 instance",
        "Add the permission to the role so that the change will take effect automatically",
        "Add the permission to the role. Hibernate and restart the existing EC2 instance.",
        "Add the permission to the S3 bucket. Restart the EC2 instance."
      ],
      "correctAnswer": ["Add the permission to the role so that the change will take effect automatically"]
    }
  },
  {
    "id": "1096",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer wishes to get a list of objects from an Amazon DynamoDB tables global secondary index. Which DynamoDB API call should the developer use to utilize the fewest read capacity units possible?",
      "answers": [
        "Scan operation using eventually-consistent reads",
        "Query operation using strongly-consistent reads",
        "Query operation using eventually-consistent reads",
        "Scan operation using strongly-consistent reads"
      ],
      "correctAnswer": ["Query operation using eventually-consistent reads"]
    }
  },
  {
    "id": "1097",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 2",
      "question": "A corporation is deploying one of their apps using AWS CodePipeline. The delivery pipeline is triggered by modifications to the master branch of an AWS CodeCommit repository and utilizes AWS CodeBuild for the test and build phases, as well as AWS CodeDeploy for application deployment. For many months, the pipeline has operated effectively with no adjustments. AWS CodeDeploy failed to deploy the updated application as planned after a recent modification to the applications source code. What may be the underlying causes? (Select two.)",
      "answers": [
        "The change was not made in the master branch of the AWS CodeCommit repository.",
        "One of the earlier stages in the pipeline failed and the pipeline has terminated.",
        "One of the Amazon EC2 instances in the companys AWS CodePipeline cluster is inactive.",
        "The AWS CodePipeline is incorrectly configured and is not executing AWS CodeDeploy.",
        "AWS CodePipeline does not have permissions to access AWS CodeCommit."
      ],
      "correctAnswer": ["The change was not made in the master branch of the AWS CodeCommit repository.",
        "One of the earlier stages in the pipeline failed and the pipeline has terminated."]
    }
  },
  {
    "id": "1098",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer is attempting to use the SDK to perform API requests. The applications IAM user credentials need multi-factor authentication for all API requests. Which mechanism does the developer use to get access to the API that is protected by multi-factor authentication?",
      "answers": [
        "GetFederationToken",
        "GetCallerIdentity",
        "GetSessionToken",
        "DecodeAuthorizationMessage"
      ],
      "correctAnswer": ["GetSessionToken"]
    }
  },
  {
    "id": "1099",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "There are two categories of members on a video-hosting website: those who pay a charge and those who do not. Each video upload creates a message in Amazon Simple Queue Service (SQS). Each video is processed by a fleet of Amazon EC2 instances that poll Amazon SQS. The developer must guarantee that the developer processes the films submitted by paying users first. How is the developer to achieve this criterion?",
      "answers": [
        "Create two SQS queues: one for paying members, and one for non-paying members. Poll the paying member queue first and then poll the non-paying member queue.",
        "Use SQS to set priorities on individual items within a single queue; give the paying members videos the highest priority.",
        "Use SQS to set priorities on individual items within a single queue and use Amazon SNS to encode the videos.",
        "Create two Amazon SNS topics: one for paying members and one for non-paying members. Use SNS topic subscription priorities to differentiate between the two types of members."
      ],
      "correctAnswer": ["Create two SQS queues: one for paying members, and one for non-paying members. Poll the paying member queue first and then poll the non-paying member queue."]
    }
  },
  {
    "id": "1100",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A development team is composed of ten individuals. The manager want to offer access to user-specific folders in an Amazon S3 bucket, similar to a home directory for each team member. The sample of the IAM policy for the team member with the username TeamMemberX is as follows: { SID: AllowS3ActionToFolders, Effect: Allow, Action: [s3: *], Resource: [arn:aws::s3:::company-name/home/TeamMemberX/*] } Rather of generating unique policies for each team member, how may this policy excerpt be made general for all team members?",
      "answers": [
        "Use IAM policy condition",
        "Use IAM policy principal",
        "Use IAM policy variables",
        "Use IAM policy resource"
      ],
      "correctAnswer": ["Use IAM policy variables"]
    }
  },
  {
    "id": "1101",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "The development team is now hard at work developing an API that will be provided through the Amazon API gateway. Three environments will service the API: development, test, and production. All three phases of the API Gateway are set to consume 237 GB of cache. Which deployment option is the MOST cost-effective?",
      "answers": [
        "Create a single API Gateway with all three stages.",
        "Create three API Gateways, one for each stage in a single AWS account.",
        "Create an API Gateway in three separate AWS accounts.",
        "Enable the cache for development and test environments only when needed."
      ],
      "correctAnswer": ["Enable the cache for development and test environments only when needed."]
    }
  },
  {
    "id": "1102",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "On Amazon EC2 ECS, two containerized microservices are hosted. The first microservice reads a database instance from Amazon RDS Aurora, while the second microservice reads a table from Amazon DynamoDB. How can the bare minimal rights be provided to each microservice?",
      "answers": [
        "Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
        "Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
        "Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
        "Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB."
      ],
      "correctAnswer": ["Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB."]
    }
  },
  {
    "id": "1103",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 2",
      "question": "A developer is debugging a three-tier application hosted on Amazon EC2 instances. Between the application servers and database servers, there is a connection issue. Which Amazon Web Services (AWS) services or tools should be utilized to determine which component is faulty? (Make a selection of at least two.)",
      "answers": [
        "AWS CloudTrail",
        "AWS Trusted Advisor",
        "Amazon VPC Flow Logs",
        "Network access control lists",
        "AWS Config rules"
      ],
      "correctAnswer": ["Amazon VPC Flow Logs",
        "Network access control lists"]
    }
  },
  {
    "id": "1104",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A program inserts data into an Amazon DynamoDB database. As the application expands to thousands of instances, intermittent ThrottlingException problems are thrown by calls to the DynamoDB API. The application is written in a language that is not supported by the AWS SDK. What procedure should be followed in the event of an error?",
      "answers": [
        "Add exponential backoff to the application logic",
        "Use Amazon SQS as an API message bus",
        "Pass API calls through Amazon API Gateway",
        "Send the items to DynamoDB through Amazon Kinesis Data Firehose"
      ],
      "correctAnswer": ["Add exponential backoff to the application logic"]
    }
  },
  {
    "id": "1105",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer is using serverless components to create a highly secure healthcare application. This application involves writing temporary data to an AWS Lambda functions /tmp storage. How should this data be encrypted by the developer?",
      "answers": [
        "Enable Amazon EBS volume encryption with an AWS KMS CMK in the Lambda function configuration so that all storage attached to the Lambda function is encrypted.",
        "Set up the Lambda function with a role and key policy to access an AWS KMS CMK. Use the CMK to generate a data key used to encrypt all data prior to writing to /tmp storage.",
        "Use OpenSSL to generate a symmetric encryption key on Lambda startup. Use this key to encrypt the data prior to writing to /tmp storage.",
        "Use an on-premises hardware security module (HSM) to generate keys, where the Lambda function requests a data key from the HSM and uses that to encrypt data on all requests to the function."
      ],
      "correctAnswer": ["Set up the Lambda function with a role and key policy to access an AWS KMS CMK. Use the CMK to generate a data key used to encrypt all data prior to writing to /tmp storage."]
    }
  },
  {
    "id": "1106",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 2",
      "question": "A business requires security for its current website, which is hosted behind an Elastic Load Balancer. Amazon EC2 instances hosting the website are CPU restricted. How can the website be secured without raising the CPU burden on the Amazon EC2 web servers? (Select two.)",
      "answers": [
        "Configure an Elastic Load Balancer with SSL pass-through.",
        "Configure SSL certificates on an Elastic Load Balancer.",
        "Configure an Elastic Load Balancer with a Loadable Storage System.",
        "Install SSL certificates on the EC2 instances.",
        "Configure an Elastic Load Balancer with SSL termination."
      ],
      "correctAnswer": ["Configure SSL certificates on an Elastic Load Balancer.", "Configure an Elastic Load Balancer with SSL termination."]
    }
  },
  {
    "id": "1107",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A software engineer created a Node.js AWS Lambda function to do CPU-intensive data processing. The Lambda function takes around 5 minutes to finish with the default parameters. Which strategy should a developer employ to expedite the finishing process?",
      "answers": [
        "Instead of using Node.js, rewrite the Lambda function using Python.",
        "Instead of packaging the libraries in the ZIP file with the function, move them to a Lambda layer and use the layer with the function.",
        "Allocate the maximum available CPU units to the function.",
        "Increase the available memory to the function."
      ],
      "correctAnswer": ["Increase the available memory to the function."]
    }
  },
  {
    "id": "1108",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer will handle AWS services through the AWS CLI on a local development server. What can be done to guarantee that the CLI executes commands using the Developers IAM permissions?",
      "answers": [
        "Specify the Developers IAM access key ID and secret access key as parameters for each CLI command.",
        "Run the aws configure CLI command, and provide the Developers IAM access key ID and secret access key.",
        "Specify the Developers IAM user name and password as parameters for each CLI command.",
        "Use the Developers IAM role when making the CLI command."
      ],
      "correctAnswer": ["Run the aws configure CLI command, and provide the Developers IAM access key ID and secret access key."]
    }
  },
  {
    "id": "1109",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A client wishes to host its source code on AWS Elastic Beanstalk. The client should undertake deployment with minimum downtime and should keep application access logs exclusively on existing instances. Which deployment strategy would meet these criteria?",
      "answers": [
        "Rolling",
        "All at once",
        "Rolling with an additional batch",
        "Immutable"
      ],
      "correctAnswer": ["Rolling"]
    }
  },
  {
    "id": "1110",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A development team chooses to use AWS CodePipeline and AWS CodeCommit to implement a continuous integration/continuous delivery (CI/CD) method for a new application. Management, on the other hand, requires a human to evaluate and approve the code prior to it being released to production. How can the development team include a manual approver into the continuous integration/continuous delivery pipeline?",
      "answers": [
        "Use AWS SES to send an email to approvers when their action is required. Develop a simple application that allows approvers to accept or reject a build. Invoke an AWS Lambda function to advance the pipeline when a build is accepted.",
        "If approved, add an approved tag when pushing changes to the CodeCommit repository. CodePipeline will proceed to build and deploy approved commits without interruption.",
        "Add an approval step to CodeCommit. Commits will not be saved until approved.",
        "Add an approval action to the pipeline. Configure the approval action to publish to an Amazon SNS topic when approval is required. The pipeline execution will stop and wait for an approval."
      ],
      "correctAnswer": ["Add an approval action to the pipeline. Configure the approval action to publish to an Amazon SNS topic when approval is required. The pipeline execution will stop and wait for an approval."]
    }
  },
  {
    "id": "1111",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 2",
      "question": "A developer is now working on a serverless Java app. Initial testing indicates that a cold start for AWS Lambda functions takes around 8 seconds on average. What should the developer do to lessen the time required for a cold start? (Select two.)",
      "answers": [
        "Add the Spring Framework to the project and enable dependency injection.",
        "Reduce the deployment package by including only needed modules from the AWS SDK for Java.",
        "Increase the memory allocation setting for the Lambda function.",
        "Increase the timeout setting for the Lambda function.",
        "Change the Lambda invocation mode from synchronous to asynchronous."
      ],
      "correctAnswer": ["Reduce the deployment package by including only needed modules from the AWS SDK for Java.",
        "Increase the memory allocation setting for the Lambda function."]
    }
  },
  {
    "id": "1112",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A business created an online event platform. The firm conducts quizzes and creates leaderboards based on the quiz results for each event. The organization maintains leaderboard data in Amazon DynamoDB and preserves it for 30 days after the conclusion of an event. The firm then deletes the outdated leaderboard data through a scheduled process. The DynamoDB table has a fixed write capacity defined. When the scheduled deletion task runs during months with a high volume of events, the DynamoDB write API calls are throttled. A developer must construct a long-term solution that permanently deletes historical leaderboard data and maximizes write performance. Which solution satisfies these criteria?",
      "answers": [
        "Configure a TTL attribute for the leaderboard data.",
        "Use DynamoDB Streams to schedule and delete the leaderboard data.",
        "Use AWS Step Functions to schedule and delete the leaderboard data.",
        "Set a higher write capacity when the scheduled delete job runs."
      ],
      "correctAnswer": ["Configure a TTL attribute for the leaderboard data."]
    }
  }
]