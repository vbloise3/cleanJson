[
  {
    "id": "679",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "After several weeks of working on a model for genome mapping, you believe you have perfected it and now want to deploy it to a platform that will provide the highest performance. Which of the following AWS platforms will provide the highest performance for this compute-intensive model?",
      "answers": [
        "EC2 M2 Instance",
        "EC2 X1 Instance",
        "EC2 P2 Instance",
        "EC2 G3 Instance",
        "EC2 F1 instance"
      ],
      "correctAnswer": ["EC2 F1 instance"]
    }
  },
  {
    "id": "680",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "Creating an S3 VPC Endpoint in your VPC will have which of the following impacts?",
      "answers": [
        "Reduce security",
        "Increase egress costs",
        "Reduce egress costs",
        "Improve security",
        "Increase latency"
      ],
      "correctAnswer": ["Reduce egress costs",
        "Improve security"]
    }
  },
  {
    "id": "681",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are helping a client troubleshoot a security configuration issue in an IAM policy for a group of users. The users assigned to the policy cannot create models. Which of the following might indicate a problem in the IAM policy?",
      "answers": [
        "The Principle element is missing",
        "The SID does not match across the policy",
        "There are multiple elements within the Statement element",
        "The Resource element is a wildcard",
        "The iam:PassRole is not explicitly allowed"
      ],
      "correctAnswer": ["The iam:PassRole is not explicitly allowed"]
    }
  },
  {
    "id": "682",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have setup autoscaling for your deployed model using SageMaker Hosting Services. You notice that in times of heavy load spikes, it takes a long time for the hosted model to scale out in response to the load. How might you increase the reaction time of auto-scaling?",
      "answers": [
        "Create a new target metric based on time since last scale event",
        "Change the timeout in the auto-scaling Lambda function",
        "Disable CloudWatch advanced tracking metrics",
        "Change the scale metric from InvocationsPerInstance to MemoryUtilization",
        "Reduce the cooldown period for automatic scaling"
      ],
      "correctAnswer": ["Reduce the cooldown period for automatic scaling"]
    }
  },
  {
    "id": "683",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have setup a group of SageMaker Notebook instances for your companys data scientists. You wanted to uphold your companys philosophy on least privilege and disabled Internet access for the notebooks. However, the data scientists report that they are unable to import certain key libraries from the Internet into their notebooks. What is the most efficient path?",
      "answers": [
        "Create a VPC Gateway Endpoint that bridges between the VPC and the desired Internet location of the required libraries",
        "Advise the data scientists that it is not possible to import libraries from the internet given the companys least privilege philosophy",
        "Create a NAT gateway within the Notebook VPC and associated default route to the NAT gateway",
        "Suggest that the scientists choose different libraries that are open source and do not pose a threat to company policy",
        "Create a series of EC2 instances outside of the VPC and install Jupyter Notebook on those instances. Have the scientists use those instances instead of SageMaker"
      ],
      "correctAnswer": ["Create a NAT gateway within the Notebook VPC and associated default route to the NAT gateway"]
    }
  },
  {
    "id": "684",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You need to ensure that only certain IP addresses can access an S3 bucket used to store sensitive model training data. What type of IAM policy would you use?",
      "answers": [
        "Role-based policy",
        "Account-based policy",
        "Identity-based policy",
        "Resource-based policy",
        "User-based policy"
      ],
      "correctAnswer": ["Resource-based policy"]
    }
  },
  {
    "id": "685",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are building out a machine learning model using multiple algorithms. You are at the point where you feel like one of the models is ready for production but you want to test difference variants of the model and compare the inference results in a testing environment before launching into production. What is the simplest way for you to test different model variants before launching into production.",
      "answers": [
        "Use Amazon SageMaker to deploy the different versions of the model to a multiple endpoints. Use a Network Load Balancer to route a percentage of traffic to each model. Evaluate the results and use Route53 to route 100 percent of traffic to higher evaluated model.",
        "Use Amazon SageMaker to deploy the different versions of the model to a multiple endpoints. Use a Application Load Balancer to route a percentage of traffic to each model. Evaluate the results and use Route53 to route 100 percent of traffic to higher evaluated model.",
        "Use multiple EC2 instances to deploy the model on Deep Learning AMIs. Evaluate the results and reroute 100 percent of traffic to higher evaluated model.",
        "Use Amazon SageMaker to deploy the different versions of the model to a single endpoint and route a percentage of traffic to each model. Evaluate the results and reroute 100 percent of traffic to higher evaluated model."
      ],
      "correctAnswer": ["Use Amazon SageMaker to deploy the different versions of the model to a single endpoint and route a percentage of traffic to each model. Evaluate the results and reroute 100 percent of traffic to higher evaluated model."]
    }
  },
  {
    "id": "686",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have prepared a machine learning model using Amazon SageMaker and have the model artifact stored onto S3. The client you are working for wants to have to ability to run new datasets into your implemented model and make inferences on the entire dataset. The client is not worried about sub second latency, as these jobs will run late at night. What is the best option to use to achieve this?",
      "answers": [
        "Setup SageMaker hosted endpoint to make batch inference calls on entire dataset",
        "Setup Lambda function and SQS to batch the inference calls for the entire dataset. Use SageMaker hosted endpoint to make batch inference calls on queued data.",
        "Create a Amazon Machine Learning Batch prediction using the Amazon ML model and a set of input observations",
        "Create a batch transform job using the trained model and the entire dataset",
        "Setup API gateway endpoint that triggers a Lambda function. Setup the Lambda function to call the SageMaker hosted endpoint to make batch inference calls on entire dataset"
      ],
      "correctAnswer": ["Create a batch transform job using the trained model and the entire dataset"]
    }
  },
  {
    "id": "687",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are consulting for a large intelligence organization that has very strict rules around how data must be handled. One such rule is that data cannot be allowed to transit the public internet. What might you suggest as they are setting up SageMaker Notebook instances?",
      "answers": [
        "Route 53 Weighted Routing",
        "AWS CloudTrail",
        "VPC Interface Endpoints",
        "AWS Macie",
        "API Gateway",
        "VPC Log Monitoring"
      ],
      "correctAnswer": ["VPC Interface Endpoints"]
    }
  },
  {
    "id": "688",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are working on a project for a client that wants to collect metadata for speeches given at various medical conferences around the world. The company wants to extract key entities for a search engine targeted to an English-speaking population even though the speeches are given in the local language which may be French, Italian, English, German or Korean. What collection of services would best fit this use-case?",
      "answers": [
        "Amazon Transcribe -> Amazon Textract",
        "Amazon Macie -> Amazon Personalize -> Amazon Comprehend",
        "Amazon Lex -> Amazon Polly -> Amazon Transcribe",
        "Amazon Comprehend -> Amazon Translate -> Amazon Lex",
        "Amazon Transcribe -> Amazon Translate -> Amazon Comprehend"
      ],
      "correctAnswer": ["Amazon Transcribe -> Amazon Translate -> Amazon Comprehend"]
    }
  },
  {
    "id": "689",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "Your company is preparing for a new release of a very key machine learning service that is sold to other organizations on a SaaS basis. Because company reputation is at stake, it is critical that the updates are not used in production until regression testing has shown that the updates perform as good as the existing model. Which validation strategy would you choose?",
      "answers": [
        "Make use of backtesting with historic data.",
        "Use a rolling upgrade to determine if the model is ready for production.",
        "Use a canary deployment to collect data on whether the model is ready for production.",
        "Deploy using a Big Bang method and quickly rollback if customers report errors.",
        "Use an A/B test to expose the updates to real-world traffic.",
        "Use a K-Fold validation method."
      ],
      "correctAnswer": ["Make use of backtesting with historic data.",
      "Use a K-Fold validation method."]
    }
  },
  {
    "id": "690",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "Your company currently owns a fleet of restaurant supply delivery trucks that deliver fresh produce to restaurants across the city. You have developed a ML model to dynamically control the temperature of the refrigeration unit on the truck which could have huge cost savings. The model is based on XGBoost and you would like to deploy the model on each truck using a locally installed Raspberry Pi. Is this feasible given current technology?",
      "answers": [
        "No, XGBoost cannot be compiled to run on an ARM processor. It can only run on x86 architectures.",
        "No, a Raspberry Pi is not powerful enough to run an ML model using XGBoost.",
        "Yes, you can deploy the model using Amazon Robomaker using the native ARM support.",
        "Yes, you can use SageMaker Neo to compile the model into a format that is optimized for the ARM processor on the Raspberry Pi.",
        "No, best practice says that you should not deploy ML models into the field but rather use a centralized inference landscape."
      ],
      "correctAnswer": ["Yes, you can use SageMaker Neo to compile the model into a format that is optimized for the ARM processor on the Raspberry Pi."]
    }
  },
  {
    "id": "691",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have been asked to provide some objective analysis of whether customers like or dislike a companys recent product launches by reviewing social media posts. What is the most efficient way to provide this analysis?",
      "answers": [
        "Amazon Textract",
        "Amazon Compilation",
        "Amazon Comprehend",
        "SageMaker Seq2Seq",
        "SageMaker BlazingText",
        "SageMaker Neo"
      ],
      "correctAnswer": ["Amazon Comprehend"]
    }
  },
  {
    "id": "692",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are helping a customer with some significant modernization efforts. They want to implement a way to forecast future production demand based on historical data. However, they do not presently have budget for a full-time data scientist or machine learning expert. What might you recommend in this situation?",
      "answers": [
        "Recommend they continue to pay you indefinitely while you develop and adjust a linear regression forecasting model.",
        "Recommend they investigate Amazon Forecast.",
        "Recommend they investigate Amazon Personalize.",
        "Recommend they send a supply chain planner to get a degree in Data Science.",
        "Recommend they deploy a model based on DeepAR using competitor data that was offered by an ex-employee."
      ],
      "correctAnswer": ["Recommend they investigate Amazon Forecast."]
    }
  },
  {
    "id": "693",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "Your organization has the need to set up a petabyte scaled BI and dashboard analysis tool that will query millions of rows of data spread across thousands of files stored in S3. Your organization wants to save as much money as possible. Which solution will allows developers to run dozens if not hundreds or thousands of queries per day, and possibly scanning many TBs of data each, while still being cost effective?",
      "answers": [
        "Data Pipeline and RDS",
        "S3 Analytics",
        "EC2 Spot instances and Presto",
        "AWS Glue Data Catalog and Amazon Athena"
      ],
      "correctAnswer": ["EC2 Spot instances and Presto"]
    }
  },
  {
    "id": "694",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are a machine learning specialist designing a regression model to predict the sales for an upcoming summer sale. The data from the past sales consists of 1,000 records containing 20 numeric attributes. As you start to analyze the data, you discovered that 30 records have values that are above the top upper whisker in the box plot upper quartile. You confirm with management that these records are unusual, but certainly valid values. There are also 78 records where another numerical value is blank. What should you do to correct these problems?",
      "answers": [
        "Drop the unusual records and fill in the blank values with 0",
        "Drop the unusual records and replace the blank values with the mean value",
        "Drop the unusual records and replace the blank values with separate Boolean values",
        "Use the unusual data and replace the missing values with a separate Boolean variable"
      ],
      "correctAnswer": ["Drop the unusual records and replace the blank values with the mean value"]
    }
  },
  {
    "id": "695",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have a data set with one column missing 30% of its data. You notice that the missing features can be determined from other features in the data set. What can you do to replace the values that will cause least amount of bias?",
      "answers": [
        "removing the items with missing values",
        "multiple data imputations",
        "use mean value",
        "last observed carried forward"
      ],
      "correctAnswer": ["multiple data imputations"]
    }
  },
  {
    "id": "696",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have been given a dataset and are in the stages of analyzing it. This dataset has around 200 features in both numeric and categorical formats. You decide to perform dimensionality reduction on the dataset hoping it will help create a more robust machine learning model. Which of the following techniques would perform better for reducing dimensions of our dataset?",
      "answers": [
        "Using the cartesian product of different features to create more relevant features",
        "Removing columns with dissimilar data trends",
        "Removing columns which have too many missing values",
        "Removing columns which have high variance in data"
      ],
      "correctAnswer": ["Removing columns which have too many missing values"]
    }
  },
  {
    "id": "697",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 3",
      "question": "What needs to be done to the following phrase before using it in your machine learning process? The quk BROWN FOX jumped over the lazy dog.",
      "answers": [
        "Replace each word with a respective n-gram vector",
        "Apply mapping of stop words",
        "Lowercase transformation",
        "One-hot encode values",
        "Replace each word with a respective tf-idf vector",
        "Create tokens from each value",
        "Fix the quk to quick"
      ],
      "correctAnswer": ["Apply mapping of stop words",
      "Lowercase transformation",
      "Create tokens from each value"]
    }
  },
  {
    "id": "698",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "A term frequency–inverse document frequency (tf–idf) matrix using trigrams is built from a text corpus consisting of the following three documents: { Hold please }, { Please try again }, { Please call us back }. What are the dimensions of the tf–idf vector/matrix?",
      "answers": [
        "(3, 3)",
        "(3, 16)",
        "(3, 9)",
        "(3, 2)",
        "(9, 3)"
      ],
      "correctAnswer": ["(3, 3)"]
    }
  },
  {
    "id": "699",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have been tasked with creating a labeled dataset by classifying text data into different categories depending on the summary of the corpus. You plan to use this data with a particular machine learning algorithm within AWS. Your goal is to make this as streamlined as possible with minimal amount of setup from you and your team. What tool can be used to help label your dataset with the minimum amount of setup?",
      "answers": [
        "AWS Comprehend entity detection",
        "Amazon Latent Dirichlet Allocation (LDA) algorithm",
        "AWS Comprehend sentiment analysis",
        "AWS SageMaker GroundTruth text classification job",
        "Amazon Neural Topic Modeling (NTM) built-in algorithm",
        "Marketplace AMI for NLP problems"
      ],
      "correctAnswer": ["AWS SageMaker GroundTruth text classification job"]
    }
  },
  {
    "id": "700",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You work for an organization that handles highly sensitive information on a daily basis. The company has different compliance rules that require all data be encrypted at rest. When preparing your machine learning models using SageMaker, how can you achieve these requirements?",
      "answers": [
        "Unmount the EBS volume from SageMaker Notebook instance, encrypt it with a KMS key, and reattach to SageMaker Notebook instance",
        "Ensure the role associated with the SageMaker Notebook instance is assigned to the customer managed key in KMS",
        "Create a customer managed key in KMS and use it when creating your SageMaker Notebook instance",
        "Stop your SageMaker notebook instance, create a customer managed key in KMS and attach it to the stopped SageMaker Notebook instance"
      ],
      "correctAnswer": ["Create a customer managed key in KMS and use it when creating your SageMaker Notebook instance"]
    }
  },
  {
    "id": "701",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "You are a Data Scientist working on a model that predicts normal and abnormal behaviors during operational hours. In the dataset, 97% of the samples observed were labeled as normal and the other 3% was classified as abnormal. Which of the following actions should help address the imbalance of data while minimizing the information loss?",
      "answers": [
        "Reach out to the company that provided the data, requesting more samples of abnormal operational behaviors.",
        "Remove all abnormal behavioral samples and perform classification training using only the normal behavior samples.",
        "Remove normal behavior samples until the normal and abnormal sample amounts match.",
        "Use the Semantic Segmentation algorithm on your dataset.",
        "Implement approaches for creating synthetic samples, such as oversampling."
      ],
      "correctAnswer": ["Reach out to the company that provided the data, requesting more samples of abnormal operational behaviors.",
      "Implement approaches for creating synthetic samples, such as oversampling."]
    }
  },
  {
    "id": "702",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have recently started a training job for a machine learning model in an Amazon SageMaker Jupyter notebook. What is the easiest way to visualize memory utilization, CPU, and training metrics?",
      "answers": [
        "Push CloudWatch logs to S3 and use QuickSight to visualize the metrics",
        "Use CloudWatch logs and Kafka",
        "Setup CloudWatch dashboard",
        "Stream Kinesis Delivery Stream to stream instance and training metrics to S3. Use QuickSight to visualize the metrics."
      ],
      "correctAnswer": ["Setup CloudWatch dashboard"]
    }
  },
  {
    "id": "703",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 3",
      "question": "During the data analysis portion of your machine learning process you have several hundred compressed JSON files stored in Amazon S3 around 200 MB in size. These files are categorised as semi-structured data and have already been crawled by AWS Glue to determine the schema associated with it. You have been using Amazon Athena to query your Amazon S3 data but finding it extremely expensive scanning 10 or more GBs of data each query. What are some techniques you can perform to cut down query execution costs?",
      "answers": [
        "Break files into smaller files",
        "Convert files to CSV",
        "Convert files to Apache Parquet or Apache ORC",
        "Decompress and split files",
        "Only include columns in the queries being run that you need",
        "Partition your data"
      ],
      "correctAnswer": ["Convert files to Apache Parquet or Apache ORC",
      "Only include columns in the queries being run that you need",
      "Partition your data"]
    }
  },
  {
    "id": "704",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are a machine learning specialist finding ways to detect anomalous data points within a given labeled data set. You have been tasked with creating a model to achieve this and also determine how accurate the model is along with other metrics like precision, recall, and F1-score metrics on the labeled data. How can this easily be achieved?",
      "answers": [
        "Create a model using the Random Cut Forest (RCF) algorithm with both a train and the optional test data channels. Use application/json for training and validation data. Train the model on an ml.m4 or ml.c4 instance type.",
        "Create a model using the Random Cut Forest (RCF) algorithm with both a train and the optional test data channels. Use text/csv for training and validation data. Train the model on an ml.m4 or ml.c4 instance type.",
        "Create a model using the XGBoost algorithm with both a train and the optional test data channels. Use application/x-recordio-protobuf for training and validation data. Train the model on an ml.m4 or ml.g4 instance type.",
        "Create a model using the XGBoost algorithm with both a train and optional validation channels. Use application/x-recordio-protobuf for training and validation data. Train the model on an ml.c4 or ml.g4 instance type.",
        "Create a model using the Random Cut Forest (RCF) algorithm with a single train channel. Use application/x-recordio-protobuf for training and validation data. Train the model on an ml.m4 or ml.c4 instance type."
      ],
      "correctAnswer": ["Create a model using the Random Cut Forest (RCF) algorithm with both a train and the optional test data channels. Use text/csv for training and validation data. Train the model on an ml.m4 or ml.c4 instance type."]
    }
  },
  {
    "id": "705",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are reviewing the evaluation metrics associated with a recently trained model. You decide to plot the points associated with the number of epochs (on the x axis) and the log loss (on the y axis) for both training and testing data. You notice as the log loss decreases as the number of epochs increases for both training and testing. You notice the log loss starts to level out around 7 epochs but continues to process over 100 epochs. What should be done to improve training time?",
      "answers": [
        "Stop training at an earlier epoch",
        "Increase the number of epochs",
        "Decrease the learning rate",
        "Increase the learning rate",
        "Evaluate a new evaluation metric rather than log loss"
      ],
      "correctAnswer": ["Stop training at an earlier epoch"]
    }
  },
  {
    "id": "706",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are applying text transformation on corpus data before using it in Amazon SageMaker BlazingText algorithm. The corpus data consists of 3 attributes (label index, title, and abstract) with the labeled index mapping to either Film, Music, or Art. What does the BlazingText algorithm expect as training data when applying supervised training with File Mode?",
      "answers": [
        "A single preprocessed text file with space-separated tokens where the training file should contain a training sentence per line along with the labels. Labels are words that are prefixed by the string __label__.",
        "A single preprocessed text file with tokenized vectors for the word frequencies for the title and abstract attributes per line. Each line should also have the one-hot encoded labeled indexes.",
        "Multiple text files with space-separated tokens where each file should contain a training sentence per line along with the labels. Labels are words that are prefixed by the string __label__.",
        "Create a manifest file that should be in JSON Lines format in which each line represents one sample. The sentences are specified using the label and source tag. The source tag will present the title and abstract. The label tag will represent the labeled index."
      ],
      "correctAnswer": ["A single preprocessed text file with space-separated tokens where the training file should contain a training sentence per line along with the labels. Labels are words that are prefixed by the string __label__."]
    }
  },
  {
    "id": "707",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are preparing plain text corpus data to build a model for Amazons Neural Topic Model (NTM) algorithm. What are the steps you need to take before the data is ready for training?",
      "answers": [
        "First tokenize the corpus data. Then, count the occurrence of each token and form bag-of-words vectors. Use these vectors as training data.",
        "First normalize the corpus data. Then, count the occurrence of each of the value produced, creating word count vectors. Use these vectors as training data.",
        "First create bigrams of the corpus data. Then, count the occurrence of each bigram produced, creating word count vectors. Use these vectors as training data.",
        "First perform tf-idf to remove words that are not important. Use the number of unique n-grams to create vectors and respective word counts. Use these vectors as training data."
      ],
      "correctAnswer": ["First tokenize the corpus data. Then, count the occurrence of each token and form bag-of-words vectors. Use these vectors as training data."]
    }
  },
  {
    "id": "708",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are consulting with a large financial institution on a ML model using a built-in SageMaker algorithm. They have asked for help deciding which hyperparameters and ranges to use in an automatic model tuning job. What can you recommend to help them get started?",
      "answers": [
        "Use a Bayesian approach when choosing target parameters and recommended ranges.",
        "Consult the documentation regarding the tunable parameters and recommended ranges.",
        "Use a random approach when choosing parameters and recommended ranges.",
        "All algorithm hyperparameters are available for auto-tuning but you must choose the proper target metric scale.",
        "Use a stochastic approach when choosing target parameters and recommended ranges."
      ],
      "correctAnswer": ["Consult the documentation regarding the tunable parameters and recommended ranges."]
    }
  },
  {
    "id": "709",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are working with a machine learning team training an image classification model using MXNet on Amazon SageMaker. The requirements state that the model should be at least 85% accurate. The data appears to be of good quality, but the accuracy is around 48% during training with the test data. Most of the time wrong labels are being predicted. What should be done to help increase the accuracy of the model?",
      "answers": [
        "Use Amazon SageMakers automatic model tuning. Take the best performing hyperparameters and run multiple training jobs in parallel using Apache Spark and Spark ML",
        "Use Amazon SageMakers automatic model tuning. Take the best performing hyperparameters and manually adjust them to meet your requirements.",
        "Use Amazon SageMakers automatic model tuning. Specify the object metric and take the best performing parameters suggested by the service to use when training the model",
        "Use Amazon SageMakers automatic model tuning. Use AWS Batch to run multiple batches of the training data with different hyper parameters specified during the autotuning job."
      ],
      "correctAnswer": ["Use Amazon SageMakers automatic model tuning. Specify the object metric and take the best performing parameters suggested by the service to use when training the model"]
    }
  },
  {
    "id": "710",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "What is a good target metric to use generally when comparing different regression models?",
      "answers": [
        "Recall",
        "Root Mean Squared Error (RMSE)",
        "F1 score",
        "Area Under the Curve (AUC)"
      ],
      "correctAnswer": ["Root Mean Squared Error (RMSE)"]
    }
  },
  {
    "id": "711",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are consulting for a restaurant chain that is expanding into new metropolitan areas. Your task is to help them decide where to place the restaurants based on proximity to competitor restaurants. They want to locate their stores within 1km of a competitors restaurant. What algorithm might you choose to help with this?",
      "answers": [
        "K-Nearest Neighbor",
        "You would not need machine learning for this project.",
        "Random Cut Forest",
        "K-Means",
        "IP Insights"
      ],
      "correctAnswer": ["You would not need machine learning for this project."]
    }
  },
  {
    "id": "712",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "When evaluating a model after the training and testing process, you notice that the error rate during training is high but the error rate during testing is low. Which of the following could be the reason for obtaining these error rates?",
      "answers": [
        "You should train for a longer period of time.",
        "You have a programmatic issue with your algorithm.",
        "Your model is overfitting the training data.",
        "You need to re-evaluate the section of your algorithm.",
        "Your model is underfitting the testing data.",
        "You have a data issue with both your training and testing datasets."
      ],
      "correctAnswer": ["You have a programmatic issue with your algorithm.",
      "You have a data issue with both your training and testing datasets."]
    }
  },
  {
    "id": "713",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have build two slightly different models for performing multi-class classification. What metric would be the most holistic for evaluating the models against each other?",
      "answers": [
        "Macro F1 Score",
        "Recall",
        "Retention",
        "Precision",
        "k-Fold Cross-validation"
      ],
      "correctAnswer": ["Macro F1 Score"]
    }
  },
  {
    "id": "714",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "For a hyperparameter optimization job, you have selected 20 hyperparameters to optimize. Unfortunately, after several hours, the values suggested by the job do not yield a better error rate when submitting the training job. What should you do to improve the optimization process?",
      "answers": [
        "Reduce the amount of training data used to train the model.",
        "Limit the number of hyperparameters to a smaller quantity and rerun.",
        "Select another algorithm that supports hyperparameter optimization.",
        "Implement an Elastic Interface to help the optimization job.",
        "Choose a smaller range for the hyperparameters and rerun."
      ],
      "correctAnswer": ["Limit the number of hyperparameters to a smaller quantity and rerun.",
      "Choose a smaller range for the hyperparameters and rerun."]
    }
  },
  {
    "id": "715",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "Which of the following could be used in an API to determine if a used cars price is within market value or not?",
      "answers": [
        "Historic Forecasting",
        "Linear Regression",
        "Multi-class Classification",
        "Binary Classification",
        "One-Hot Encoding",
        "Polynomial Synthesis",
        "Logistic Regression"
      ],
      "correctAnswer": ["Binary Classification",
        "Logistic Regression"]
    }
  },
  {
    "id": "716",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are trying to follow an old family recipe for making sourdough bread. The recipe states that you should add enough water to the flour such that it is slightly sticky. Which if the following best characterizes this instruction?",
      "answers": [
        "Reinforcement Learning",
        "Metric",
        "Heuristic",
        "Algorithm",
        "Unsupervised Learning",
        "Supervised Learning"
      ],
      "correctAnswer": ["Heuristic"]
    }
  },
  {
    "id": "717",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "A machine learning specialist is running a training job on a single EC2 instance using their own Tensorflow code on a Deep Learning AMI. The specialist wants to run distributed training and inference using SageMaker. What should the machine learning specialist do?",
      "answers": [
        "Ensure both the SageMaker Notebook instance and EC2 instance have the same role assigned to them. Use Notebook peering to gain access to run scripts from SageMaker on the EC2 instance",
        "It is not possible to run custom Tensorflow code in SageMaker",
        "Use Tensorflow in SageMaker and edit your code to run using the SageMaker Python SDK",
        "Use Tensorflow in SageMaker and run your code as a script",
        "Use Tensorflow in SageMaker and modify the AWS Deep Learning Docker containers"
      ],
      "correctAnswer": ["Use Tensorflow in SageMaker and edit your code to run using the SageMaker Python SDK"]
    }
  },
  {
    "id": "718",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "You want to design a model that will predict the price of a used car based on attributes of the car as a linear regression model. Which of the following algorithms could you use for your car price prediction model?",
      "answers": [
        "BlazingText",
        "Seq2Seq",
        "Linear Learner",
        "NTM",
        "XGBoost"
      ],
      "correctAnswer": ["Linear Learner",
      "XGBoost"]
    }
  },
  {
    "id": "719",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are designing a machine learning model to dynamically translate from a variety of languages to Klingon. What algorithm might be the best approach for this use-case?",
      "answers": [
        "NTM",
        "AWS Translate",
        "BlazingText",
        "LDA",
        "Seq2Seq"
      ],
      "correctAnswer": ["Seq2Seq"]
    }
  },
  {
    "id": "720",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "In a regression problem, we have plotted the residuals in a histogram and observed that a distribution is heavily skewed to the left of zero. What does this tell us about our model?",
      "answers": [
        "Our model is consistently overestimating.",
        "Our model is not perfect but still well within the area under the curve.",
        "Our model is sufficient with regard to aggregate residual.",
        "Our model is sufficient with regard to RMSE.",
        "Our model is consistently underestimating."
      ],
      "correctAnswer": ["Our model is consistently overestimating."]
    }
  },
  {
    "id": "721",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "The performance of your Linear Learner training process is way too slow. What might you do to speed up the training process but not sacrifice accuracy?",
      "answers": [
        "Change from a binary classifier to a multiclass classifier.",
        "Increase the softmax loss hyperparameter.",
        "Decrease the learning rate hyperparameter.",
        "Increase the learning rate hyperparameter.",
        "Convert the training data from CSV to recordIO-protobuf format."
      ],
      "correctAnswer": ["Convert the training data from CSV to recordIO-protobuf format."]
    }
  },
  {
    "id": "722",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You need to organize a large set of data into 5 groupings that are more similar than dissimilar. How might you frame this problem?",
      "answers": [
        "Linear Regression",
        "Logical Regression",
        "Multi-class Classification",
        "Binary Classification",
        "Clustering"
      ],
      "correctAnswer": ["Clustering"]
    }
  },
  {
    "id": "723",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "A company is building an application that allows high school students to view programming videos to learn more about coding. The instructors upload videos directly to the platform. You have been tasked with designing a model to determine whether the videos uploaded are safe for viewing by high school students. It is critical that no inappropriate videos make it onto the platform. Which is the MOST important metric to evaluate during the machine learning process for this task?",
      "answers": [
        "Precision",
        "Accuracy",
        "AUC/ROC",
        "Recall"
      ],
      "correctAnswer": ["Recall"]
    }
  },
  {
    "id": "724",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have developed a very complex deep learning model but your accuracy levels are still not at your desired target levels, even after hyperparameter optimization. What is the most likely cause?",
      "answers": [
        "Hyperparameter optimization is not performing as documented.",
        "You did not employ a warm start method for your first optimization job.",
        "A random approach for hyperparameter optimization versus a Bayesian approach.",
        "Hyperparameter tuning is not flawless and can still fail to converse on the best answer."
      ],
      "correctAnswer": ["Hyperparameter tuning is not flawless and can still fail to converse on the best answer."]
    }
  },
  {
    "id": "725",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "After evaluating a training job, you realize that your model is overfitting. You suspect that its due to the very high number of features in the dataset. What might be a way you can reduce dimensionality for the dataset?",
      "answers": [
        "LDA",
        "One-hot Encoding",
        "PCA",
        "NTM",
        "Object2Vec",
        "Softmax function"
      ],
      "correctAnswer": ["PCA"]
    }
  },
  {
    "id": "726",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "Which of the following is NOT a valid use-case for incremental training?",
      "answers": [
        "Train a new model using an expanded dataset that contains an underlying pattern that was not accounted for in the previous training and which resulted in poor model performance.",
        "Resume a training job that was stopped.",
        "Train several variants of a model, either with different hyperparameter settings or using different datasets.",
        "Rebuilt model artifacts which you have accidentally deleted.",
        "Use the model artifacts or a portion of the model artifacts from a popular publicly available model in a training job. You do not need to train a new model from scratch."
      ],
      "correctAnswer": ["Rebuilt model artifacts which you have accidentally deleted."]
    }
  },
  {
    "id": "727",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have been asked to review some documentation prepared by a customer on using SageMaker. Above all, this customer wants very stable, proven processes--nothing cutting edge. Which of the following document excerpts would give you concern?",
      "answers": [
        "When launching a training job, always ensure that the job is producing log entries before you assume that it is running successfully.",
        "When deploying to a production environment, always specify two or more instances.",
        "Train several variants of a model, either with different hyperparameter settings or using different datasets.",
        "When specifying the container path, always consult the documentation as to the proper path.",
        "When specifying the container path, always use the :latest tag."
      ],
      "correctAnswer": ["When specifying the container path, always use the :latest tag."]
    }
  },
  {
    "id": "728",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "You need to extract keywords from a collection of news stories. Which of the following algorithms could you use for this?",
      "answers": [
        "WWF",
        "LDA",
        "RCF",
        "NTM",
        "PCA"
      ],
      "correctAnswer": ["LDA",
      "NTM"]
    }
  },
  {
    "id": "729",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You need to organize a large set of data into 6 groupings that are more similar than dissimilar. What algorithm approach might you use for this problem? You also don not have any ground truth data available for this task.",
      "answers": [
        "Multi-Class Classification",
        "K-Nearest Neighbor",
        "K-Means",
        "Random Cut Forest",
        "Linear Regression"
      ],
      "correctAnswer": ["K-Means"]
    }
  },
  {
    "id": "730",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "After you have trained your model, you observe that you reached convergence rather quickly then loss flattened out. You suspect your model is not as accurate as it could be. Which of the following is your most likely next step?",
      "answers": [
        "Increase the learning rate and retrain.",
        "Switch to GPU instances for training",
        "Lower the learning rate and retrain.",
        "Add additional CPU instances for training."
      ],
      "correctAnswer": ["Lower the learning rate and retrain."]
    }
  },
  {
    "id": "731",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 3",
      "question": "You have been tasked with transforming highly sensitive data using AWS Glue. Which of the following AWS Glue settings allowing you to control encryption for your transformation process?",
      "answers": [
        "The security configurations that you create (S3 encryption, CloudWatch logs encryption, and Job bookmark encryption)",
        "The encryption of your classifier used during the transformation job",
        "Encrypting the AWS Glue development endpoints created",
        "Encryption of your Data Catalog at its components",
        "Encrypting the managed EBS volumes used to run Apache Spark environment running PySpark code",
        "The server-side encryption setting (SSE-S3 or SSE-KMS) that is passed as a parameter to your AWS Glue ETL job."
      ],
      "correctAnswer": ["The security configurations that you create (S3 encryption, CloudWatch logs encryption, and Job bookmark encryption)",
      "Encryption of your Data Catalog at its components",
      "The server-side encryption setting (SSE-S3 or SSE-KMS) that is passed as a parameter to your AWS Glue ETL job."]
    }
  },
  {
    "id": "732",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You work for a company that builds custom python libraries for transforming and preprocessing data sets before using them in BI tools and machine learning pipelines. One of your customers is using your libraries and has the need to include them within their AWS Glue pipeline. What suggestions can you make to allow your customers to use your libraries within their AWS Glue pipelines?",
      "answers": [
        "AWS Glue does not support custom code outside of PySpark and Scala implemented libraries",
        "Give the custom code to the customer allowing the customers to upload the code onto AWS Glue and use within an ETL job.",
        "Upload the custom library as a .zip archive onto S3. Before your customers create an ETL job, include the S3 link as a script library and job parameter",
        "Upload all of the library files onto S3. Before your customers create an ETL job, include the S3 link as a script library and job parameter"
      ],
      "correctAnswer": ["Upload the custom library as a .zip archive onto S3. Before your customers create an ETL job, include the S3 link as a script library and job parameter"]
    }
  },
  {
    "id": "733",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "You are in charge of training a deep learning (DL) model at scale using massively large datasets. These datasets are too large to load into memory on your Notebook instances. What are some best practices to use to solve this problem and still have fast training times?",
      "answers": [
        "Pack the data in parallel, distributed across multiple machines and split the data into a small number of files with a uniform number of partitions.",
        "Use a fleet of RAM intensive ml.m5 EC2 instances with MapReduce and Hadoop installed onto them. Load the data in parallel to the cluster to distribute across multiple machines.",
        "Use a fleet of GPU intensive ml.p2 EC2 instances with MapReduce and Hadoop installed onto them. Load the data in parallel to the cluster to distribute across multiple machines.",
        "Once the data is split into a small number of files and partitioned, the preparation job can be parallelized and thus run faster.",
        "Once the data is loaded onto the instances, split the data into a small number of files and partitioned, then the preparation job can be parallelized and thus run faster."
      ],
      "correctAnswer": ["Pack the data in parallel, distributed across multiple machines and split the data into a small number of files with a uniform number of partitions.",
      "Once the data is split into a small number of files and partitioned, the preparation job can be parallelized and thus run faster."]
    }
  },
  {
    "id": "734",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have JSON data that needs to be streamed into S3 in parquet format. How could you do this using the least effort?",
      "answers": [
        "Use Kinesis Data Stream to ingest the data and Kinesis Data Firehose as a delivery stream. Once data lands onto S3, use AWS Glue to transform the data through preconfigured job.",
        "Use Kinesis Data Stream to ingest the data and Kinesis Data Firehose as a delivery stream. Once data is uploaded to S3, trigger a Lambda function that converts the data from JSON to parquet format.",
        "Use Kinesis Firehose as delivery stream. Enable record transformation that references a table stored in Apache Hive metastore in EMR.",
        "Setup EMR cluster that uses Apache Streaming to stream data onto cluster. Create an Apache Spark job to convert the JSON to parquet format using an Apache Hive metastore to determine the schema of the JSON data.",
        "Use Kinesis Firehose as delivery stream. Enable record transformation that references a table stored in AWS Glue defining the schema for your source records."
      ],
      "correctAnswer": ["Use Kinesis Firehose as delivery stream. Enable record transformation that references a table stored in AWS Glue defining the schema for your source records."]
    }
  },
  {
    "id": "735",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You have been tasked with collecting 100-byte events from hundreds or thousands of low power devices and writing records into a Kinesis stream. You have Amazon Elastic Compute Cloud (EC2) instances serving as a proxy for these events. You must add logic for batching or multithreading, in addition to retry logic and record de aggregation at the consumer side. Which service can you use to handle all of this for you?",
      "answers": [
        "Using the Kinesis Producer Library (KPL)",
        "Using the APIs for Kinesis Streams",
        "Using the Kinesis Client Library (KCL)",
        "Using EMR cluster as intermediate logic mechanism",
        "Using the Amazon Kinesis Agent",
        "Using a combination of SQS and Lambda for retry logic and batching respectively."
      ],
      "correctAnswer": ["Using the Kinesis Producer Library (KPL)"]
    }
  },
  {
    "id": "736",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 4",
      "question": "You need to implement transformations for data that is hosted in Amazon S3 and an Amazon RDS MySQL instance. Which of the following needs to occur to achieve this?",
      "answers": [
        "Define an Redshift cluster to COPY the data from S3 and RDS into Redshift tables",
        "You must create two separate transformation jobs. AWS Glue only processes one data store at a time.",
        "Define an AWS Glue Crawler to populate the AWS Glue Data Catalog with tables.",
        "Define an AWS Glue Job to transform the data that uses these Data Catalog tables as sources and targets",
        "Ensure that the role you pass to the crawler has permission to access Amazon S3 paths.",
        "Ensure that the JDBC connection the crawler uses has the correct username and password credentials to access the RDS instance",
        "Define an EMR cluster using Apache Hive to create metadata tables and Apache Spark to transform the data."
      ],
      "correctAnswer": ["Define an AWS Glue Crawler to populate the AWS Glue Data Catalog with tables.",
      "Define an AWS Glue Job to transform the data that uses these Data Catalog tables as sources and targets",
      "Ensure that the role you pass to the crawler has permission to access Amazon S3 paths.",
      "Ensure that the JDBC connection the crawler uses has the correct username and password credentials to access the RDS instance"]
    }
  },
  {
    "id": "737",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "How can a Juypter Notebook instance read data from an S3 bucket encrypted with SSE-KMS?",
      "answers": [
        "Use a VPC Gateway Endpoint.",
        "Import an external key into KMS and use it to securely read the data.",
        "Ensure the Notebook instance role is associated with the KMS key.",
        "Encrypted data in S3 cannot be accessed through Notebook instances.",
        "Ensure the Notebook instance role is an administrator who can administer the KMS key."
      ],
      "correctAnswer": ["Ensure the Notebook instance role is associated with the KMS key."]
    }
  },
  {
    "id": "738",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are part of a Machine Learning team that has several large CSV datasets in Amazon S3. The team have been using these files to build a model in Amazon SageMaker using the Linear Learner algorithm. The time it takes to train these models is taking hours to complete. The teams leaders need to accelerate the training process. What can a Machine Learning Specialist do to address this concern?",
      "answers": [
        "Create SageMaker Hyperparameter auto tuning job using ml.m5 instance types to find optimized hyperparameter.",
        "Use Amazon Machine Learning to train the models.",
        "Use AWS Glue to transform the data from the CSV format into JSON.",
        "Use Amazon Kinesis to stream the data into Amazon SageMaker.",
        "Use Amazon SageMakers Pipe input mode."
      ],
      "correctAnswer": ["Use Amazon SageMakers Pipe input mode."]
    }
  },
  {
    "id": "739",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 3",
      "question": "You are a machine learning specialist evaluating a current model that has been deployed into production. It has been deployed for a few weeks now and the results are not accurate and sometimes the inference data is missing values. What are some techniques you can review to help solve this problem?",
      "answers": [
        "Ensure the extraction methods used to generate the training datasets are the same as for the production inference data.",
        "Ensure the target variable used as the predictor during training represents the actual outcome that the machine learning model is trying to predict.",
        "Ensure the training data has a 50/50 distribution of the target attribute.",
        "Ensure the inference data is in the exact same for as the training and testing data",
        "Ensure the inference data has placeholder values for any of the missing values",
        "Ensure the training datasets are large, representative samples of the populations that the model needs to make predictions."
      ],
      "correctAnswer": ["Ensure the extraction methods used to generate the training datasets are the same as for the production inference data.",
      "Ensure the target variable used as the predictor during training represents the actual outcome that the machine learning model is trying to predict.",
      "Ensure the training datasets are large, representative samples of the populations that the model needs to make predictions."]
    }
  },
  {
    "id": "740",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are training a model using a dataset with credit card numbers stored in Amazon S3. What should be done to ensure these credit cards are encrypted before and during model training?",
      "answers": [
        "Ensure the S3 bucket and data has a SSE-KMS key associated with it and specify the same SSE-KMS Key ID when you create the SageMaker notebook instance and training job.",
        "Create a Lambda function that is invoked when the training job starts to apply SSE-KMS key to the data before starting the training process.",
        "Create a SageMaker notebook instance with a SSE-KMS key associated with it. After loading the S3 data onto the notebook instance encrypt is using SSE-KMS before feeding it into the training job.",
        "When calling the SageMaker SDK training job ensure the SSE-KMS is used as a parameter during the creation of the training job."
      ],
      "correctAnswer": ["Ensure the S3 bucket and data has a SSE-KMS key associated with it and specify the same SSE-KMS Key ID when you create the SageMaker notebook instance and training job."]
    }
  },
  {
    "id": "741",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 3",
      "question": "You are working for an online shopping platform that records actions made by its users. This information is captured in multiple JSON files stored in S3. You have been tasked with moving this data into Amazon Redshift database tables as part of a data lake migration process. Which of the following needs to occur to achieve this in the most efficient way?",
      "answers": [
        "Setup DynamoDB table and use Data Pipeline to load the S3 data into DynamoDB table.",
        "Launch an Amazon Redshift cluster and create database tables.",
        "Use COPY commands to load the tables from the data files on DynamoDB.",
        "Use COPY commands to load the tables from the data files on Amazon S3.",
        "Troubleshoot load errors and modify your COPY commands to correct the errors.",
        "Use multiple concurrent COPY commands to load the table from each JSON file.",
        "Use the INSERT command to load the tables from the data files on Amazon S3."
      ],
      "correctAnswer": ["Launch an Amazon Redshift cluster and create database tables.",
      "Use COPY commands to load the tables from the data files on Amazon S3.",
      "Troubleshoot load errors and modify your COPY commands to correct the errors."]
    }
  },
  {
    "id": "742",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "You are a machine learning specialist that needs to setup an ETL pipeline for your organization using Amazon Elastic Map Reduce (EMR). You must connect the EMR cluster to Amazon SageMaker without writing any specific code. Which framework allows you to achieve this?",
      "answers": [
        "Apache Pig",
        "Apache Flink",
        "Apache Hive",
        "Apache Spark",
        "Apache Mahout"
      ],
      "correctAnswer": ["Apache Spark"]
    }
  },
  {
    "id": "743",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 2",
      "question": "You are a data scientist that has been tasked with setting up an Amazon Elastic Map Reduce (EMR) cluster to host your organizations data lake. You also need to setup this cluster for machine learning processes and it has been decided to use Amazon SageMaker libraries as the machine learning platform. What steps do you need to take to start using SageMaker with your EMR cluster data lake?",
      "answers": [
        "Run your SageMaker Spark application on EMR by submitting your Spark application jar and any additional dependencies your Spark application uses",
        "Use Apache Mahout within an EMR Notebook to train and infer your model",
        "Ensure the EMR cluster and SageMaker hosted model are in the same region to make successful inferences",
        "Download the aws-sagemaker-spark-sdk component along with Spark on your EMR cluster",
        "Convert EMR DataFrame to CSV and use that to train and infer your model"
      ],
      "correctAnswer": ["Run your SageMaker Spark application on EMR by submitting your Spark application jar and any additional dependencies your Spark application uses",
      "Download the aws-sagemaker-spark-sdk component along with Spark on your EMR cluster"]
    }
  }
]