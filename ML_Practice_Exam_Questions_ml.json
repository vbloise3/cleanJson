[
  {
    "id": "1173",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A status dashboard is shown by an application. A 1 KB message from a SQS queue is used to update the status. Although the status changes seldom, the Developer must keep the time between the message's arrival in the queue and the dashboard update as short as possible. Which strategy results in the smallest delay between dashboard updates?",
      "answers": [
        "Retrieve the messages from the queue using long polling every 20 seconds.",
        "Reduce the size of the messages by compressing them before sending.",
        "Retrieve the messages from the queue using short polling every 10 seconds.",
        "Reduce the size of each message payload by sending it in two parts."
      ],
      "correctAnswer": ["Retrieve the messages from the queue using long polling every 20 seconds."]
    }
  },
  {
    "id": "1174",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 2",
      "question": "A firm is introducing the option to save currency (or gift cards) to its very successful casual gaming website. Users must be able to exchange this value for the goods of other users on the site. This would involve either updating both users' information in a single transaction or totally rolling back both users' records. Which AWS database choices provide the needed transactional capabilities for this new feature? (Select two.)",
      "answers": [
        "Amazon DynamoDB with operations made with the ConsistentRead parameter set to true",
        "Amazon ElastiCache for Memcached with operations made within a transaction block",
        "Amazon Aurora MySQL with operations made within a transaction block",
        "Amazon DynamoDB with reads and writes made using Transact* operations",
        "Amazon Redshift with operations made within a transaction block."
      ],
      "correctAnswer": ["Amazon Aurora MySQL with operations made within a transaction block", "Amazon DynamoDB with reads and writes made using Transact* operations"]
    }
  },
  {
    "id": "1175",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "On Amazon ECS, a corporation is running a Docker application. The applications load must be scaled depending on the past 15 seconds user activity. How should a developer instrument code to ensure it satisfies the requirement?",
      "answers": [
        "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds",
        "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds",
        "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds",
        "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds"
      ],
      "correctAnswer": ["Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds"]
    }
  },
  {
    "id": "1176",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer must construct an AWS application that will consume Amazon SQS messages ranging in size from 1KB to 1GB. How should Amazon Simple Queue Service (SQS) messages be managed?",
      "answers": [
        "Use Amazon S3 and the Amazon SQS CLI.",
        "Use Amazon S3 and the Amazon SQS Extended Client Library for Java.",
        "Use Amazon EBS and the Amazon SQS CLI.",
        "Use Amazon EFS and the Amazon SQS CLI."
      ],
      "correctAnswer": ["Use Amazon S3 and the Amazon SQS Extended Client Library for Java."]
    }
  },
  {
    "id": "1177",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer is using AWS CLI, however it is stalling out when performing list commands on a large number of resources. How can this time-out be avoided?",
      "answers": [
        "Use pagination",
        "Use shorthand syntax",
        "Use parameter values",
        "Use quoting strings"
      ],
      "correctAnswer": ["Use pagination"]
    }
  },
  {
    "id": "1178",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer has developed a Lambda function and is discovering that it is taking longer than planned to execute. The Developer determined that increasing computing capacity might enhance performance after some debugging. What is the best way for the developer to boost Lambda computing resources?",
      "answers": [
        "Run on a larger instance size with more compute capacity.",
        "Increase the maximum execution time.",
        "Specify a larger compute capacity when calling the Lambda function.",
        "Increase the allocated memory for the Lambda function."
      ],
      "correctAnswer": ["Increase the allocated memory for the Lambda function."]
    }
  },
  {
    "id": "1179",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A business builds, bundles, and packages its apps on-premises and stores them locally using a third-party technology. The firm runs its front-end apps on Amazon EC2 instances. How does one deploy an application from the source control system to the EC2 instances?",
      "answers": [
        "Use AWS CodeDeploy and point it to the local storage to directly deploy a bundle in a .zip, .tar, or .tar.gz format.",
        "Upload the bundle to an Amazon S3 bucket and specify the S3 location when doing a deployment using AWS CodeDeploy.",
        "Create a repository using AWS CodeCommit to automatically trigger a deployment to the EC2 instances.",
        "Use AWS CodeBuild to automatically deploy the latest build to the latest EC2 instances."
      ],
      "correctAnswer": ["Upload the bundle to an Amazon S3 bucket and specify the S3 location when doing a deployment using AWS CodeDeploy."]
    }
  },
  {
    "id": "1180",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer is using Amazon API Gateway to create a WebSocket API. The payload submitted to this API is JSON with an action key included. This key may take on one of three values: create, update, or delete. The developer must interact with several routes dependent on the value of the incoming JSON payload's action key. How can the developer execute this operation using the LESS settings possible?",
      "answers": [
        "Deploy the WebSocket API to three stages for the respective routes: create, update, and remove",
        "Create a new route key and set the name as action",
        "Set the value of the route selection expression to action",
        "Set the value of the route selection expression to $request.body.action"
      ],
      "correctAnswer": ["Set the value of the route selection expression to $request.body.action"]
    }
  },
  {
    "id": "1181",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "Amazon Kinesis Data Streams enables an application to ingest and handle huge streams of data records in real time. Utilizing the Amazon Kinesis Client Library, Amazon EC2 instances ingest and process data from the shards of the Kinesis data stream (KCL). The program manages failure situations and eliminates the need for backup personnel. The program indicates that a particular shard is getting much more data than anticipated. The hot shard is resharded to react to variations in the pace of data flow. If the initial number of shards in the Kinesis data stream is four, and the number of shards increases to six after resharding, what is the maximum number of EC2 instances that can be deployed to process data from all the shards?",
      "answers": [
        "12",
        "6",
        "4",
        "1"
      ],
      "correctAnswer": ["6"]
    }
  },
  {
    "id": "1182",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A developer is constructing a template for the AWS Serverless Application Model (AWS SAM). Multiple AWS Lambda functions, an Amazon S3 bucket, and an Amazon CloudFront distribution are defined in the AWS SAM template. One of the Lambda functions is executed on the CloudFront distribution's Lambda@Edge. The S3 bucket is specified as the CloudFront distribution's origin. While the developer installs the AWS SAM template in the eu-west-1 Region, the developer encounters an error when attempting to create the stack. What may have precipitated this problem?",
      "answers": [
        "CloudFront distributions can be created only in the us-east-1 Region.",
        "Lambda@Edge functions can be created only in the us-east-1 Region.",
        "A single AWS SAM template cannot contain multiple Lambda functions.",
        "The CloudFront distribution and the S3 bucket cannot be created in the same Region."
      ],
      "correctAnswer": ["Lambda@Edge functions can be created only in the us-east-1 Region."]
    }
  },
  {
    "id": "1183",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A business provides services to a large number of downstream customers. Each customer has the option of connecting to one or more services. As a result, a complicated architecture that is difficult to manage and scales poorly has emerged. To administer various customer services, the organization requires a single interface. Which AWS service should this architecture be refactored with?",
      "answers": [
        "AWS Lambda",
        "AWS X-Ray",
        "Amazon SQS",
        "Amazon API Gateway"
      ],
      "correctAnswer": ["Amazon API Gateway"]
    }
  },
  {
    "id": "1184",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A corporation has automated their release pipelines using AWS CodePipeline. The development team is currently developing an AWS Lambda function that will deliver alerts when the status of each stage's action changes. How do I correlate the Lambda function with the event source?",
      "answers": [
        "Create a trigger that invokes the Lambda function from the Lambda console by selecting CodePipeline as the event source.",
        "Create an event trigger and specify the Lambda function from the CodePipeline console.",
        "Create an Amazon CloudWatch alarm that monitors status changes in Code Pipeline and triggers the Lambda function.",
        "Create an Amazon CloudWatch Events rule that uses CodePipeline as an event source."
      ],
      "correctAnswer": ["Create an Amazon CloudWatch Events rule that uses CodePipeline as an event source."]
    }
  },
  {
    "id": "1185",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "On the website of a worldwide ecommerce corporation, users are encouraged to post evaluations for things they have bought. Seasonal products are available. Products are popular for a brief period of time and then go out of favor the following season. Customers provide feedback in their native tongue. A developer is using Amazon Translate to construct a new function that will translate customer feedback into more languages. The website now features hundreds of thousands of goods and millions of reviews. The majority of reviews will be seen in one or two languages. How can this new feature be implemented in the MOST cost-effective manner possible?",
      "answers": [
        "Update the application code that writes the review to the database to translate the review into all supported languages. Persist a copy of each translation in the database for future visitors.",
        "Update the application code that reads the review from the database to check an Amazon ElastiCache cluster for translated reviews. If a visitor is requesting a review and language combination that is not in the cache, configure the application to translate it and store it in the cache with a TTL of 1 month.",
        "Update the application code that reads the review from the database to translate the review in real time and return the translated version without persisting it.",
        "Set up a database change stream to write events to a stream each time a customer writes a review. Configure an AWS Lambda function to read the events from the stream, translate the review into all supported languages, and update the review database to include all translations for future visitors."
      ],
      "correctAnswer": ["Update the application code that reads the review from the database to translate the review in real time and return the translated version without persisting it."]
    }
  },
  {
    "id": "1186",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A custom library is used by an application to perform HTTP calls directly to AWS service endpoints. The program is suffering transitory problems, which cause processes to halt when they are encountered for the first time. The application has been requested to be more robust by adding error retries and exponential backoff. How should a developer apply the modifications with the LITTLEEST amount of custom code possible?",
      "answers": [
        "Add a Retry-After HTTP header to API requests",
        "Use the AWS CLI to configure the retry settings in a named profile",
        "Change the custom library to retry on 5xx errors only",
        "Use an AWS SDK and set retry-specific configurations"
      ],
      "correctAnswer": ["Use an AWS SDK and set retry-specific configurations"]
    }
  },
  {
    "id": "1187",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A business demands that AWS Lambda functions built by developers record problems in order for System Administrators to resolve issues more efficiently. What should developers do to address this need?",
      "answers": [
        "Publish errors to a dedicated Amazon SQS queue.",
        "Create an Amazon CloudWatch Events event trigger based on certain Lambda events.",
        "Report errors through logging statements in Lambda function code.",
        "Set up an Amazon SNS topic that sends logging statements upon failure."
      ],
      "correctAnswer": ["Report errors through logging statements in Lambda function code."]
    }
  },
  {
    "id": "1188",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "In the console, a developer transformed an existing application to an AWS Lambda function. While the application works OK on a local laptop, it fails to import a module when evaluated in the Lambda interface. Which of the following may be used to correct the error?",
      "answers": [
        "Install the missing module and specify the current directory as the target. Create a ZIP file to include all files under the current directory, and upload the ZIP file.",
        "Install the missing module in a lib directory. Create a ZIP file to include all files under the lib directory, and upload the ZIP file as dependency file.",
        "In the Lambda code, invoke a Linux command to install the missing modules under the /usr/lib directory.",
        "In the Lambda console, create a LB_LIBRARY_PATH environment and specify the value for the system library path."
      ],
      "correctAnswer": ["Install the missing module and specify the current directory as the target. Create a ZIP file to include all files under the current directory, and upload the ZIP file."]
    }
  },
  {
    "id": "1189",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A gaming business is in the process of creating a mobile game application for the iOS and Android operating systems. This mobile game encrypts user data and keeps it locally on the device. The business wants consumers to be able to play the game on numerous devices. Without developing a backend application, the organization needs to synchronize user data across devices. Which Amazon Web Services (AWS) offering or functionality should the business use to achieve these requirements?",
      "answers": [
        "AWS Lambda@Edge",
        "Amazon S3 Transfer Acceleration",
        "Amazon DynamoDB Accelerator (DAX)",
        "AWS Amplify with AWS AppSync"
      ],
      "correctAnswer": ["AWS Amplify with AWS AppSync"]
    }
  },
  {
    "id": "1190",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "There are three separate environments in a company: development, quality assurance, and production. The company wishes to deploy its code in three stages: development, QA, and finally production. What AWS service may be used to fulfill this need?",
      "answers": [
        "Use AWS CodeCommit to create multiple repositories to deploy the application.",
        "Use AWS CodeBuild to create, configure, and deploy multiple build application projects.",
        "Use AWS Data Pipeline to create multiple data pipeline provisions to deploy the application.",
        "Use AWS CodeDeploy to create multiple deployment groups."
      ],
      "correctAnswer": ["Use AWS CodeDeploy to create multiple deployment groups."]
    }
  },
  {
    "id": "1191",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "An application is composed of two components: one for handling HTTP requests and another for doing background processing operations. Each component must be self-scaling. The developer want to use AWS Elastic Beanstalk to deploy this application. How, in light of these criteria, should this application be deployed?",
      "answers": [
        "Deploy the application in a single Elastic Beanstalk environment.",
        "Deploy each component in a separate Elastic Beanstalk environment.",
        "Use multiple Elastic Beanstalk environments for the HTTP component, but one environment for the background task component.",
        "Use multiple Elastic Beanstalk environments for the background task component, but one environment for the HTTP component."
      ],
      "correctAnswer": ["Deploy each component in a separate Elastic Beanstalk environment."]
    }
  },
  {
    "id": "1192",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Test Example Questions",
      "questionType": "multiple choice 1",
      "question": "A business runs a bespoke application on a series of on-premises Linux servers that are connected to Amazon API Gateway through Amazon API Gateway. On the API test stage, AWS X-Ray tracing has been enabled. How can a developer implement X-Ray tracing with the LEAST amount of setup on on-premises servers?",
      "answers": [
        "Install and run the X-Ray SDK on the on-premises servers to capture and relay the data to the X-Ray service.",
        "Install and run the X-Ray daemon on the on-premises servers to capture and relay the data to the X-Ray service.",
        "Capture incoming requests on-premises and configure an AWS Lambda function to pull, process, and relay relevant data to X-Ray using the PutTraceSegments API call.",
        "Capture incoming requests on-premises and configure an AWS Lambda function to pull, process, and relay relevant data to X-Ray using the PutTelemetryRecords API call."
      ],
      "correctAnswer": ["Install and run the X-Ray daemon on the on-premises servers to capture and relay the data to the X-Ray service."]
    }
  }
]